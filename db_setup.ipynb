{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_59081/3664004303.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The `airflow.operators.dummy_operator.DummyOperator` class is deprecated. Please use `</span><span style=\"color: #808000; text-decoration-color: #808000\">'airflow.operators.empty.EmptyOperator'</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_59081/\u001b[0m\u001b[1;33m3664004303.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m3\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: The `airflow.operators.dummy_operator.DummyOperator` class is deprecated. Please use `\u001b[0m\u001b[33m'airflow.operators.empty.EmptyOperator'\u001b[0m\u001b[33m`.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from airflow.decorators import task\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.providers.common.sql.operators.sql import BaseSQLOperator\n",
    "from airflow.models import Connection\n",
    "from datetime import datetime, timedelta\n",
    "import Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/tmpdm1yc02e\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (68.1.2)\n",
      "Requirement already satisfied: pip in /opt/homebrew/lib/python3.11/site-packages (23.2.1)\n",
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!python3 -m ensurepip --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements.  See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership.  The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied.  See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License.\n",
    "\"\"\"\n",
    "### Tutorial Documentation\n",
    "Documentation that goes along with the Airflow tutorial located\n",
    "[here](https://airflow.apache.org/tutorial.html)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "# [START tutorial]\n",
    "# [START import_module]\n",
    "import textwrap\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# The DAG object; we'll need this to instantiate a DAG\n",
    "from airflow.models.dag import DAG\n",
    "\n",
    "# Operators; we need this to operate!\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "# [END import_module]\n",
    "\n",
    "\n",
    "# [START instantiate_dag]\n",
    "with DAG(\n",
    "    dag_id=\"wx\",\n",
    "    # [START default_args]\n",
    "    # These args will get passed on to each operator\n",
    "    # You can override them on a per-task basis during operator initialization\n",
    "    default_args={\n",
    "        \"depends_on_past\": False,\n",
    "        \"email\": [\"airflow@example.com\"],\n",
    "        \"email_on_failure\": False,\n",
    "        \"email_on_retry\": False,\n",
    "        \"retries\": 1,\n",
    "        \"retry_delay\": timedelta(minutes=5),\n",
    "        # 'queue': 'bash_queue',\n",
    "        # 'pool': 'backfill',\n",
    "        # 'priority_weight': 10,\n",
    "        # 'end_date': datetime(2016, 1, 1),\n",
    "        # 'wait_for_downstream': False,\n",
    "        # 'sla': timedelta(hours=2),\n",
    "        # 'execution_timeout': timedelta(seconds=300),\n",
    "        # 'on_failure_callback': some_function, # or list of functions\n",
    "        # 'on_success_callback': some_other_function, # or list of functions\n",
    "        # 'on_retry_callback': another_function, # or list of functions\n",
    "        # 'sla_miss_callback': yet_another_function, # or list of functions\n",
    "        # 'on_skipped_callback': another_function, #or list of functions\n",
    "        # 'trigger_rule': 'all_success'\n",
    "    },\n",
    "    # [END default_args]\n",
    "    description=\"A simple tutorial DAG\",\n",
    "    schedule=timedelta(days=1),\n",
    "    start_date=datetime(2021, 1, 1),\n",
    "    catchup=False,\n",
    "    tags=[\"example\"],\n",
    ") as dag:\n",
    "    # [END instantiate_dag]\n",
    "\n",
    "    # t1, t2 and t3 are examples of tasks created by instantiating operators\n",
    "    # [START basic_task]\n",
    "    t1 = BashOperator(\n",
    "        task_id=\"print_date\",\n",
    "        bash_command=\"date\",\n",
    "    )\n",
    "\n",
    "    t2 = BashOperator(\n",
    "        task_id=\"sleep\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=\"sleep 5\",\n",
    "        retries=3,\n",
    "    )\n",
    "    # [END basic_task]\n",
    "\n",
    "    # [START documentation]\n",
    "    t1.doc_md = textwrap.dedent(\n",
    "        \"\"\"\\\n",
    "    #### Task Documentation\n",
    "    You can document your task using the attributes `doc_md` (markdown),\n",
    "    `doc` (plain text), `doc_rst`, `doc_json`, `doc_yaml` which gets\n",
    "    rendered in the UI's Task Instance Details page.\n",
    "    ![img](https://imgs.xkcd.com/comics/fixing_problems.png)\n",
    "    **Image Credit:** Randall Munroe, [XKCD](https://xkcd.com/license.html)\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    dag.doc_md = __doc__  # providing that you have a docstring at the beginning of the DAG; OR\n",
    "    dag.doc_md = \"\"\"\n",
    "    This is a documentation placed anywhere\n",
    "    \"\"\"  # otherwise, type it like this\n",
    "    # [END documentation]\n",
    "\n",
    "    # [START jinja_template]\n",
    "    templated_command = textwrap.dedent(\n",
    "        \"\"\"\n",
    "    {% for i in range(5) %}\n",
    "        echo \"{{ ds }}\"\n",
    "        echo \"{{ macros.ds_add(ds, 7)}}\"\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    t3 = BashOperator(\n",
    "        task_id=\"templated\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=templated_command,\n",
    "    )\n",
    "    # [END jinja_template]\n",
    "\n",
    "    t1 >> [t2, t3]\n",
    "# [END tutorial]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/2079575115.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> AirflowProviderDeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Call to deprecated class PostgresOperator. </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">Please use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `</span><span style=\"color: #808000; text-decoration-color: #808000\">hook_params</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">{</span><span style=\"color: #808000; text-decoration-color: #808000\">'schema'</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;database&gt;}</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/\u001b[0m\u001b[1;33m2079575115.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m3\u001b[0m\u001b[1;33m AirflowProviderDeprecationWarning\u001b[0m\u001b[33m: Call to deprecated class PostgresOperator. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mPlease use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `\u001b[0m\u001b[33mhook_params\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'schema'\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33mdatabase\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m`.\u001b[0m\u001b[1;33m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/2079575115.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">16</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> AirflowProviderDeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Call to deprecated class PostgresOperator. </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">Please use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `</span><span style=\"color: #808000; text-decoration-color: #808000\">hook_params</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">{</span><span style=\"color: #808000; text-decoration-color: #808000\">'schema'</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;database&gt;}</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/\u001b[0m\u001b[1;33m2079575115.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m16\u001b[0m\u001b[1;33m AirflowProviderDeprecationWarning\u001b[0m\u001b[33m: Call to deprecated class PostgresOperator. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mPlease use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `\u001b[0m\u001b[33mhook_params\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'schema'\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33mdatabase\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m`.\u001b[0m\u001b[1;33m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from airflow.providers.postgres.operators.postgres import PostgresOperator\n",
    "\n",
    "create_employees_table = PostgresOperator(\n",
    "    task_id=\"create_employees_table\",\n",
    "    postgres_conn_id=\"tutorial_pg_conn\",\n",
    "    sql=\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS employees (\n",
    "            \"Serial Number\" NUMERIC PRIMARY KEY,\n",
    "            \"Company Name\" TEXT,\n",
    "            \"Employee Markme\" TEXT,\n",
    "            \"Description\" TEXT,\n",
    "            \"Leave\" INTEGER\n",
    "        );\"\"\",\n",
    ")\n",
    "\n",
    "create_employees_temp_table = PostgresOperator(\n",
    "    task_id=\"create_employees_temp_table\",\n",
    "    postgres_conn_id=\"tutorial_pg_conn\",\n",
    "    sql=\"\"\"\n",
    "        DROP TABLE IF EXISTS employees_temp;\n",
    "        CREATE TABLE employees_temp (\n",
    "            \"Serial Number\" NUMERIC PRIMARY KEY,\n",
    "            \"Company Name\" TEXT,\n",
    "            \"Employee Markme\" TEXT,\n",
    "            \"Description\" TEXT,\n",
    "            \"Leave\" INTEGER\n",
    "        );\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/3263098348.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> AirflowProviderDeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Call to deprecated class PostgresOperator. </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">Please use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `</span><span style=\"color: #808000; text-decoration-color: #808000\">hook_params</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">{</span><span style=\"color: #808000; text-decoration-color: #808000\">'schema'</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;database&gt;}</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/\u001b[0m\u001b[1;33m3263098348.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m1\u001b[0m\u001b[1;33m AirflowProviderDeprecationWarning\u001b[0m\u001b[33m: Call to deprecated class PostgresOperator. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mPlease use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `\u001b[0m\u001b[33mhook_params\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'schema'\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33mdatabase\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m`.\u001b[0m\u001b[1;33m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_employees_table = PostgresOperator(\n",
    "    task_id=\"create_employees_table\",\n",
    "    postgres_conn_id=\"tutorial_pg_conn\",\n",
    "    sql=\"sql/employees_schema.sql\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from airflow.decorators import task\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "\n",
    "\n",
    "@task\n",
    "def get_data():\n",
    "    # NOTE: configure this as appropriate for your airflow environment\n",
    "    data_path = \"/opt/airflow/dags/files/employees.csv\"\n",
    "    os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/tutorial/pipeline_example.csv\"\n",
    "\n",
    "    response = requests.request(\"GET\", url)\n",
    "\n",
    "    with open(data_path, \"w\") as file:\n",
    "        file.write(response.text)\n",
    "\n",
    "    postgres_hook = PostgresHook(postgres_conn_id=\"tutorial_pg_conn\")\n",
    "    conn = postgres_hook.get_conn()\n",
    "    cur = conn.cursor()\n",
    "    with open(data_path, \"r\") as file:\n",
    "        cur.copy_expert(\n",
    "            \"COPY employees_temp FROM STDIN WITH CSV HEADER DELIMITER AS ',' QUOTE '\\\"'\",\n",
    "            file,\n",
    "        )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import task\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "\n",
    "\n",
    "@task\n",
    "def merge_data():\n",
    "    query = \"\"\"\n",
    "        INSERT INTO employees\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT DISTINCT *\n",
    "            FROM employees_temp\n",
    "        ) t\n",
    "        ON CONFLICT (\"Serial Number\") DO UPDATE\n",
    "        SET\n",
    "              \"Employee Markme\" = excluded.\"Employee Markme\",\n",
    "              \"Description\" = excluded.\"Description\",\n",
    "              \"Leave\" = excluded.\"Leave\";\n",
    "    \"\"\"\n",
    "    try:\n",
    "        postgres_hook = PostgresHook(postgres_conn_id=\"tutorial_pg_conn\")\n",
    "        conn = postgres_hook.get_conn()\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/558977705.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">97</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedInAirflow3Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/\u001b[0m\u001b[1;33m558977705.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m97\u001b[0m\u001b[1;33m RemovedInAirflow3Warning\u001b[0m\u001b[33m: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/558977705.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">19</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> AirflowProviderDeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Call to deprecated class PostgresOperator. </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">Please use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `</span><span style=\"color: #808000; text-decoration-color: #808000\">hook_params</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">{</span><span style=\"color: #808000; text-decoration-color: #808000\">'schema'</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;database&gt;}</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/\u001b[0m\u001b[1;33m558977705.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m19\u001b[0m\u001b[1;33m AirflowProviderDeprecationWarning\u001b[0m\u001b[33m: Call to deprecated class PostgresOperator. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mPlease use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `\u001b[0m\u001b[33mhook_params\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'schema'\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33mdatabase\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m`.\u001b[0m\u001b[1;33m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/558977705.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">32</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> AirflowProviderDeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Call to deprecated class PostgresOperator. </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">Please use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `</span><span style=\"color: #808000; text-decoration-color: #808000\">hook_params</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">{</span><span style=\"color: #808000; text-decoration-color: #808000\">'schema'</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;database&gt;}</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/z1/4b3273pd3h7fr5n27jfg1dsr0000gn/T/ipykernel_4728/\u001b[0m\u001b[1;33m558977705.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m32\u001b[0m\u001b[1;33m AirflowProviderDeprecationWarning\u001b[0m\u001b[33m: Call to deprecated class PostgresOperator. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mPlease use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `\u001b[0m\u001b[33mhook_params\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'schema'\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33mdatabase\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m`.\u001b[0m\u001b[1;33m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import pendulum\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.providers.postgres.operators.postgres import PostgresOperator\n",
    "\n",
    "\n",
    "@dag(\n",
    "    dag_id=\"process_employees\",\n",
    "    schedule_interval=\"0 0 * * *\",\n",
    "    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n",
    "    catchup=False,\n",
    "    dagrun_timeout=datetime.timedelta(minutes=60),\n",
    ")\n",
    "def ProcessEmployees():\n",
    "    create_employees_table = PostgresOperator(\n",
    "        task_id=\"create_employees_table\",\n",
    "        postgres_conn_id=\"tutorial_pg_conn\",\n",
    "        sql=\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS employees (\n",
    "                \"Serial Number\" NUMERIC PRIMARY KEY,\n",
    "                \"Company Name\" TEXT,\n",
    "                \"Employee Markme\" TEXT,\n",
    "                \"Description\" TEXT,\n",
    "                \"Leave\" INTEGER\n",
    "            );\"\"\",\n",
    "    )\n",
    "\n",
    "    create_employees_temp_table = PostgresOperator(\n",
    "        task_id=\"create_employees_temp_table\",\n",
    "        postgres_conn_id=\"tutorial_pg_conn\",\n",
    "        sql=\"\"\"\n",
    "            DROP TABLE IF EXISTS employees_temp;\n",
    "            CREATE TABLE employees_temp (\n",
    "                \"Serial Number\" NUMERIC PRIMARY KEY,\n",
    "                \"Company Name\" TEXT,\n",
    "                \"Employee Markme\" TEXT,\n",
    "                \"Description\" TEXT,\n",
    "                \"Leave\" INTEGER\n",
    "            );\"\"\",\n",
    "    )\n",
    "\n",
    "    @task\n",
    "    def get_data():\n",
    "        # NOTE: configure this as appropriate for your airflow environment\n",
    "        data_path = \"/opt/airflow/dags/files/employees.csv\"\n",
    "        os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "\n",
    "        url = \"https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/tutorial/pipeline_example.csv\"\n",
    "\n",
    "        response = requests.request(\"GET\", url)\n",
    "\n",
    "        with open(data_path, \"w\") as file:\n",
    "            file.write(response.text)\n",
    "\n",
    "        postgres_hook = PostgresHook(postgres_conn_id=\"tutorial_pg_conn\")\n",
    "        conn = postgres_hook.get_conn()\n",
    "        cur = conn.cursor()\n",
    "        with open(data_path, \"r\") as file:\n",
    "            cur.copy_expert(\n",
    "                \"COPY employees_temp FROM STDIN WITH CSV HEADER DELIMITER AS ',' QUOTE '\\\"'\",\n",
    "                file,\n",
    "            )\n",
    "        conn.commit()\n",
    "\n",
    "    @task\n",
    "    def merge_data():\n",
    "        query = \"\"\"\n",
    "            INSERT INTO employees\n",
    "            SELECT *\n",
    "            FROM (\n",
    "                SELECT DISTINCT *\n",
    "                FROM employees_temp\n",
    "            ) t\n",
    "            ON CONFLICT (\"Serial Number\") DO UPDATE\n",
    "            SET\n",
    "              \"Employee Markme\" = excluded.\"Employee Markme\",\n",
    "              \"Description\" = excluded.\"Description\",\n",
    "              \"Leave\" = excluded.\"Leave\";\n",
    "        \"\"\"\n",
    "        try:\n",
    "            postgres_hook = PostgresHook(postgres_conn_id=\"tutorial_pg_conn\")\n",
    "            conn = postgres_hook.get_conn()\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "            return 0\n",
    "        except Exception as e:\n",
    "            return 1\n",
    "\n",
    "    [create_employees_table, create_employees_temp_table] >> get_data() >> merge_data()\n",
    "\n",
    "\n",
    "dag = ProcessEmployees()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
